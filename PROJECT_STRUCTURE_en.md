# Project Structure Guide

This document explains the projectâ€™s directory layout and the purpose of the main files.

## ğŸ“ Directory Structure

```
rebuild1002/
â”œâ”€â”€ ğŸ“„ Main Application Files
â”‚   â”œâ”€â”€ app_main.py                    # App entry point (FastAPI service)
â”‚   â”œâ”€â”€ navigation_master.py           # Navigation controller (state machine)
â”‚   â”œâ”€â”€ workflow_blindpath.py          # Blind-path navigation workflow
â”‚   â”œâ”€â”€ workflow_crossstreet.py        # Crosswalk navigation workflow
â”‚   â””â”€â”€ yolomedia.py                   # Item search workflow
â”‚
â”œâ”€â”€ ğŸ™ï¸ Speech & Audio
â”‚   â”œâ”€â”€ asr_core.py                    # Speech recognition core
â”‚   â”œâ”€â”€ omni_client.py                 # Qwen-Omni client
â”‚   â”œâ”€â”€ qwen_extractor.py              # Tag extraction (Chinese â†’ English)
â”‚   â”œâ”€â”€ audio_player.py                # Audio player
â”‚   â””â”€â”€ audio_stream.py                # Audio stream manager
â”‚
â”œâ”€â”€ ğŸ¤– Models
â”‚   â”œâ”€â”€ yoloe_backend.py               # YOLO-E backend (open vocabulary)
â”‚   â”œâ”€â”€ trafficlight_detection.py      # Traffic light detection
â”‚   â”œâ”€â”€ obstacle_detector_client.py    # Obstacle detector client
â”‚   â””â”€â”€ models.py                      # Model definitions
â”‚
â”œâ”€â”€ ğŸ¥ Video Processing
â”‚   â”œâ”€â”€ bridge_io.py                   # Thread-safe frame buffers
â”‚   â”œâ”€â”€ sync_recorder.py               # A/V synchronized recording
â”‚   â””â”€â”€ video_recorder.py              # Legacy video recorder
â”‚
â”œâ”€â”€ ğŸŒ Web Frontend
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html                 # Main UI HTML
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ main.js                    # Main JS
â”‚   â”‚   â”œâ”€â”€ vision.js                  # Vision stream handling
â”‚   â”‚   â”œâ”€â”€ visualizer.js              # Data visualization
â”‚   â”‚   â”œâ”€â”€ vision_renderer.js         # Rendering
â”‚   â”‚   â”œâ”€â”€ vision.css                 # Styles
â”‚   â”‚   â””â”€â”€ models/                    # 3D models (IMU visualization)
â”‚
â”œâ”€â”€ ğŸµ Audio Assets
â”‚   â”œâ”€â”€ music/                         # System chimes
â”‚   â”‚   â”œâ”€â”€ converted_å‘ä¸Š.wav
â”‚   â”‚   â”œâ”€â”€ converted_å‘ä¸‹.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ voice/                         # Pre-recorded voice lines
â”‚       â”œâ”€â”€ voice_mapping.json
â”‚       â””â”€â”€ *.wav
â”‚
â”œâ”€â”€ ğŸ§  Model Files
â”‚   â””â”€â”€ model/
â”‚       â”œâ”€â”€ yolo-seg.pt                # Blind-path segmentation model
â”‚       â”œâ”€â”€ yoloe-11l-seg.pt           # YOLO-E open-vocabulary model
â”‚       â”œâ”€â”€ shoppingbest5.pt           # Item recognition model
â”‚       â”œâ”€â”€ trafficlight.pt            # Traffic light model
â”‚       â””â”€â”€ hand_landmarker.task       # MediaPipe hand model
â”‚
â”œâ”€â”€ ğŸ“¹ Recordings
â”‚   â””â”€â”€ recordings/                    # Auto-saved video & audio
â”‚       â”œâ”€â”€ video_*.avi
â”‚       â””â”€â”€ audio_*.wav
â”‚
â”œâ”€â”€ ğŸ› ï¸ ESP32 Firmware
â”‚   â””â”€â”€ compile/
â”‚       â”œâ”€â”€ compile.ino                # Arduino main program
â”‚       â”œâ”€â”€ camera_pins.h              # Camera pin definitions
â”‚       â”œâ”€â”€ ICM42688.cpp/h             # IMU driver
â”‚       â””â”€â”€ ESP32_VIDEO_OPTIMIZATION.md
â”‚
â”œâ”€â”€ ğŸ§ª Tests
â”‚   â”œâ”€â”€ test_recorder.py               # Recording tests
â”‚   â”œâ”€â”€ test_traffic_light.py          # Traffic light tests
â”‚   â”œâ”€â”€ test_cross_street_blindpath.py # Navigation tests
â”‚   â””â”€â”€ test_crosswalk_awareness.py    # Crosswalk awareness tests
â”‚
â”œâ”€â”€ ğŸ“š Docs
â”‚   â”œâ”€â”€ README.md                      # Main project doc
â”‚   â”œâ”€â”€ INSTALLATION.md                # Install guide
â”‚   â”œâ”€â”€ CONTRIBUTING.md                # Contribution guide
â”‚   â”œâ”€â”€ FAQ.md                         # Frequently Asked Questions
â”‚   â”œâ”€â”€ CHANGELOG.md                   # Changelog
â”‚   â”œâ”€â”€ SECURITY.md                    # Security policy
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md           # This file
â”‚
â”œâ”€â”€ ğŸ³ Docker
â”‚   â”œâ”€â”€ Dockerfile                     # Docker image
â”‚   â”œâ”€â”€ docker-compose.yml             # Docker Compose config
â”‚   â””â”€â”€ .dockerignore                  # Docker ignore list
â”‚
â”œâ”€â”€ âš™ï¸ Config
â”‚   â”œâ”€â”€ .env.example                   # Environment variable template
â”‚   â”œâ”€â”€ .gitignore                     # Git ignore list
â”‚   â”œâ”€â”€ requirements.txt               # Python deps
â”‚   â”œâ”€â”€ setup.sh                       # Linux/macOS setup script
â”‚   â””â”€â”€ setup.bat                      # Windows setup script
â”‚
â”œâ”€â”€ ğŸ“„ License
â”‚   â””â”€â”€ LICENSE                        # MIT License
â”‚
â””â”€â”€ ğŸ”§ GitHub
    â””â”€â”€ .github/
        â”œâ”€â”€ ISSUE_TEMPLATE/
        â”‚   â”œâ”€â”€ bug_report.md
        â”‚   â””â”€â”€ feature_request.md
        â””â”€â”€ pull_request_template.md
```

## ğŸ”‘ Key Files Overview

### Main Application Layer

#### `app_main.py`
- **Purpose:** FastAPI main service handling all WebSocket connections
- **Key Features:**
  - WebSocket routing (`/ws/camera`, `/ws_audio`, `/ws/viewer`, etc.)
  - Model loading & initialization
  - State coordination & management
  - Audio/video stream distribution
- **Depends on:** All other modules
- **Entry point:** `python app_main.py`

#### `navigation_master.py`
- **Purpose:** Central navigation controller; manages the system state machine
- **Primary States:**
  - IDLE â€” idle
  - CHAT â€” dialogue mode
  - BLINDPATH_NAV â€” tactile path navigation
  - CROSSING â€” crosswalk
  - TRAFFIC_LIGHT_DETECTION â€” traffic-light detection
  - ITEM_SEARCH â€” item search
- **Core Methods:**
  - `process_frame()` â€” per-frame processing
  - `start_blind_path_navigation()` â€” start tactile path navigation
  - `start_crossing()` â€” start crosswalk mode
  - `on_voice_command()` â€” handle voice commands

### Workflow Modules

#### `workflow_blindpath.py`
- **Purpose:** Core logic for tactile path navigation
- **Features:**
  - Path segmentation & detection
  - Obstacle detection
  - Turn detection
  - Optical-flow stabilization
  - Directional guidance generation
- **State Machine:**
  - ONBOARDING â€” getting onto the path
  - NAVIGATING â€” navigating along the path
  - MANEUVERING_TURN â€” handling turns
  - AVOIDING_OBSTACLE â€” obstacle avoidance

#### `workflow_crossstreet.py`
- **Purpose:** Crosswalk navigation logic
- **Features:**
  - Crosswalk detection
  - Directional alignment
  - Guidance generation
- **Core Methods:**
  - `_is_crosswalk_near()` â€” determine crosswalk proximity
  - `_compute_angle_and_offset()` â€” compute angle and lateral offset

#### `yolomedia.py`
- **Purpose:** Item search workflow
- **Features:**
  - YOLO-E prompt-based detection
  - MediaPipe hand tracking
  - Optical-flow target tracking
  - Hand guidance (direction prompts)
  - Grasp-action detection
- **Modes:**
  - `SEGMENT`, `FLASH`, `CENTER_GUIDE`, `TRACK`

### Speech / Voice Modules

#### `asr_core.py`
- **Purpose:** AliCloud Paraformer ASR (real-time speech recognition)
- **Features:**
  - Real-time transcription
  - VAD (Voice Activity Detection)
  - Result callbacks
- **Key Class:** `ASRCallback`

#### `omni_client.py`
- **Purpose:** Qwen-Omni-Turbo multimodal dialogue client
- **Features:**
  - Streaming dialogue generation
  - Image + text inputs
  - Speech output
- **Core Function:** `stream_chat()`

#### `audio_player.py`
- **Purpose:** Unified audio playback manager
- **Features:**
  - TTS playback
  - Multi-channel audio mixing
  - Volume control
  - Thread-safe playback
- **Core Functions:** `play_voice_text()`, `play_audio_threadsafe()`

### Model Backends

#### `yoloe_backend.py`
- **Purpose:** YOLO-E open-vocabulary backend
- **Features:**
  - Prompt setup
  - Real-time segmentation
  - Target tracking
- **Key Class:** `YoloEBackend`

#### `trafficlight_detection.py`
- **Purpose:** Traffic-light detection module
- **Detection Methods:**
  1. YOLO model detection
  2. HSV color classification (fallback)
- **Output:** Red / Green / Yellow / Unknown

#### `obstacle_detector_client.py`
- **Purpose:** Obstacle detection client
- **Features:**
  - Whitelist category filtering
  - In-mask (path) checks
  - Object attributes (area, position, risk)

### Video Processing

#### `bridge_io.py`
- **Purpose:** Thread-safe frame buffering & distribution
- **Features:**
  - Producerâ€“consumer pattern
  - Raw frame buffer
  - Processed frame fan-out
- **Core Functions:**
  - `push_raw_jpeg()` â€” receive ESP32 frames
  - `wait_raw_bgr()` â€” get raw frame
  - `send_vis_bgr()` â€” send processed frame

#### `sync_recorder.py`
- **Purpose:** Synchronized audio/video recording
- **Features:**
  - Sync record video & audio
  - Auto timestamped filenames
  - Thread safety
- **Outputs:** `recordings/video_*.avi`, `audio_*.wav`

### Frontend

#### `templates/index.html`
- **Purpose:** Web monitoring interface
- **Main Areas:**
  - Video stream display
  - Status panel
  - IMU 3D visualization
  - Speech recognition results

#### `static/main.js`
- **Purpose:** Main JavaScript logic
- **Features:**
  - WebSocket connection management
  - UI updates
  - Event handling

#### `static/vision.js`
- **Purpose:** Vision stream handling
- **Features:**
  - Receive video frames via WebSocket
  - Canvas rendering
  - FPS calculation

#### `static/visualizer.js`
- **Purpose:** IMU 3D visualization (Three.js)
- **Features:**
  - Receive IMU data
  - Real-time pose rendering
  - Dynamic lighting effects

## ğŸ”„ Data Flow

### Video Stream
```
ESP32-CAM
â†’ [JPEG] WebSocket /ws/camera
â†’ bridge_io.push_raw_jpeg()
â†’ yolomedia / navigation_master
â†’ bridge_io.send_vis_bgr()
â†’ [JPEG] WebSocket /ws/viewer
â†’ Browser Canvas
```
### Audio Stream (Upstream)
```
ESP32-MIC
â†’ [PCM16] WebSocket /ws_audio
â†’ asr_core
â†’ DashScope ASR
â†’ Recognition Result
â†’ start_ai_with_text_custom()
```

### Audio Stream (Downstream)

```
Qwen-Omni / TTS
â†’ audio_player
â†’ [PCM16] audio_stream
â†’ [WAV] HTTP /stream.wav
â†’ ESP32 Speaker
```


### IMU Data Stream
```
ESP32-IMU
â†’ [JSON] UDP 12345
â†’ process_imu_and_maybe_store()
â†’ [JSON] WebSocket /ws
â†’ visualizer.js (Three.js)
```

## ğŸ¯ Key Design Patterns

### 1. State Machine Pattern
- **Location:** `navigation_master.py`
- **Purpose:** Manage system state transitions  
- **States:** IDLE â†’ CHAT / BLINDPATH_NAV / CROSSING / ...

### 2. Producerâ€“Consumer Pattern
- **Location:** `bridge_io.py`
- **Purpose:** Decouple video reception and processing  
- **Implementation:** Threads + Queues

### 3. Strategy Pattern
- **Location:** Each `workflow_*.py`
- **Purpose:** Implement different navigation strategies  
- **Implementation:** Unified `process_frame()` interface

### 4. Singleton Pattern
- **Location:** Model loading
- **Purpose:** Share model instances globally  
- **Implementation:** Global variables + initialization checks

### 5. Observer Pattern
- **Location:** WebSocket communication
- **Purpose:** Allow multiple clients to subscribe to video streams  
- **Implementation:** `camera_viewers: Set[WebSocket]`

## ğŸ“¦ Dependencies
```
app_main.py
â”œâ”€â”€ navigation_master.py
â”‚   â”œâ”€â”€ workflow_blindpath.py
â”‚   â”‚   â”œâ”€â”€ yoloe_backend.py
â”‚   â”‚   â””â”€â”€ obstacle_detector_client.py
â”‚   â”œâ”€â”€ workflow_crossstreet.py
â”‚   â””â”€â”€ trafficlight_detection.py
â”œâ”€â”€ yolomedia.py
â”‚   â””â”€â”€ yoloe_backend.py
â”œâ”€â”€ asr_core.py
â”œâ”€â”€ omni_client.py
â”œâ”€â”€ audio_player.py
â”œâ”€â”€ audio_stream.py
â”œâ”€â”€ bridge_io.py
â””â”€â”€ sync_recorder.py
```

## ğŸš€ Startup Process

1. **Initialization Phase** (`app_main.py`)
   - Load environment variables  
   - Load navigation models (YOLO, MediaPipe)  
   - Initialize the audio system  
   - Start the recording system  
   - Preload the traffic light detection model  

2. **Service Launch** (FastAPI)
   - Register WebSocket routes  
   - Mount static files  
   - Start UDP listener (for IMU data)  
   - Start HTTP service (port 8081)  

3. **Runtime Phase**
   - Wait for ESP32 connection  
   - Receive video/audio/IMU data  
   - Process user voice commands  
   - Push real-time processing results  

4. **Shutdown Phase**
   - Stop recording (save files)  
   - Close all WebSocket connections  
   - Release model resources  
   - Clean up temporary files  

---

**Note:** For detailed implementation of each module, please refer to the corresponding source file comments and docstrings.
